---
title: "Duplicate detection"
output:
  html_document:
    df_print: paged
editor_options:
  chunk_output_type: inline
---
```{r setup,include=F}
library(tidyverse)
```


```{r}

md = read.csv("kdm-metadata-samples.csv", stringsAsFactors = F)
```


```{r find_dupes}
dup.ids = md %>% 
    select(ID) %>% 
    group_by(ID) %>% 
    summarise(n = n()) %>% 
    ungroup() %>% 
    filter(n > 1) %>% 
    select(ID) %>% 
    unlist %>% 
    as.character()
dup.ids
```

So we have 6 duplicated IDs
```{r}
md.dups = md %>% 
    filter(ID %in% dup.ids) %>% 
    arrange(ID)
write.csv(md.dups, "DuplicateSamples.csv", row.names = F)
```

```{r echo=F}
md.dups %>% 
    select(ID, SampleSet, Species, SpeciesNote, Location, Latitude, Longitude, Notes, SeedYesNo, SeedNotes, Sequenced) %>% 
    knitr::kable()
```

